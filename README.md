# Canvas RAG Dashboard

An AI-powered â€œretrieval-augmented generationâ€ (RAG) dashboard for Canvas LMS.  
Students can chat naturally about their courses, assignments, and profileâ€”powered by a Python FastAPI backend that fetches Canvas data and a Next.js frontend that renders a conversational UI.

---

## ğŸš€ Architecture

canvas-rag-dashboard/
â”œâ”€â”€ frontend/                      # Next.js React app
â””â”€â”€ backend/                       # Python FastAPI microservice

- **frontend/**  
  - Built with Next.js + React + Tailwind  
  - Renders a chat UI (`CanvasChat.tsx`) that sends questions to the backend  

- **backend/**  
  - FastAPI service in Python  
  - `canvas_service.py` â€“ wraps Canvas API calls (profile, courses, assignments)  
  - `app.py` â€“ exposes `/context` and `/qa` endpoints  
  - Uses LangChain, Chroma (or other vector store), and OpenAI for embeddings & QA  

---

## ğŸ“‹ Prerequisites

- **Node.js** â‰¥ 16  
- **Python** â‰¥ 3.9  
- Canvas API token and domain  
- OpenAI API key  

---

## âš™ï¸ Setup

### 1. Clone the repo

```bash
git clone https://github.com/your-org/canvas-rag-dashboard.git
cd canvas-rag-dashboard

2. Configure environment variables

Frontend (frontend/.env.local)

NEXT_PUBLIC_API_BASE=http://localhost:8000

Backend (backend/.env)

# Canvas API credentials
CANVAS_API_TOKEN=
CANVAS_DOMAIN=

# OpenAI API key
OPENAI_API_KEY=
# (Optional) FastAPI/Uvicorn settings
# PORT=8000
# HOST=0.0.0.0
# Chroma persistence
CHROMA_DB_DIR=./.chromadb


LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"
LANGSMITH_API_KEY=
LANGSMITH_PROJECT=

ğŸƒâ€â™‚ï¸ Running Locally

Backend

cd backend
python -m venv .venv
source .venv/bin/activate       # macOS/Linux
# .venv\Scripts\activate        # Windows
pip install -r requirements.txt
uvicorn app:app --reload       # starts at http://localhost:8000

Frontend

cd frontend
npm install
npm run dev                    # starts at http://localhost:3000

ğŸ§° Usage
	1.	Open your browser to http://localhost:3000
	2.	Ask questions like â€œWhat assignments do I have due soon?â€
	3.	The frontend sends your query to POST /qa on the Python service, which:
	â€¢	Fetches your Canvas context (/context)
	â€¢	Embeds and indexes documents with LangChain & Chroma
	â€¢	Runs a RetrievalQA chain via OpenAI
	â€¢	Returns a natural-language answer

ğŸ“ Folder Structure

canvas-rag-dashboard/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ .env.local
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ pages/index.tsx
â”‚       â”œâ”€â”€ components/CanvasChat.tsx
â”‚       â””â”€â”€ styles/globals.css
â””â”€â”€ backend/
    â”œâ”€â”€ .env
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ app.py
    â”œâ”€â”€ canvas_service.py
    â””â”€â”€ models/canvas_types.py

ğŸ› ï¸ Contributing
	1.	Fork the repo
	2.	Create a feature branch (git checkout -b feature/...)
	3.	Commit & push
	4.	Open a Pull Request

Please follow the existing code style and add tests for any new features.

ğŸ“„ License

This project is MIT-licensed. See LICENSE for details